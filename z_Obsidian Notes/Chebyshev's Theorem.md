Chebyshev’s theorem (also known as Chebyshev’s Inequality) states that for any probability distribution, regardless of shape (normal, skewed, uniform, etc.), at least a certain percentage of values will fall within a given number of standard deviations ($\sigma$) from the mean ($\mu$).

For a random variable $R$ with expected value $\mathbb{E}[R]$ (mean) and standard deviation $\sigma_R$​, Chebyshev’s inequality states that:

$$P(|R - \mathbb{E}[R]| \geq k\sigma_R) \leq \frac{1}{k^2}$$

where:

- $\mathbb{E}[R]$ is the **expected value** (mean) of $R$.
- $\sigma_R$​ is the **standard deviation** of $R$.
- $k$ is the number of standard deviations from the mean.