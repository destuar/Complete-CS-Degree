The **expected value** (also called the **average**) of a [[random variable]] $R$ over a [[probability space]] $S$ is the long-run average value that $R$ would take if the experiment were repeated infinitely many times. It represents the weighted average of all possible values of $R$, weighted by their probabilities.

The expected value of $R$, denoted as $E[R]$ or $\mathbb{E}[R]$, is defined as:

If $R$ is a **discrete random variable** taking values $r_1, r_2, \dots, r_n$â€‹ with probabilities $P(R = r_i)$, then the expected value is:

$$E[R] = \sum_{i} r_i P(R = r_i)$$


If $R$ is **continuous** with [[probability distribution function]] (density / PDF) $f(r)$, then the expected value is:

$$E[R] = \int_{-\infty}^{\infty} r f(r) dr$$