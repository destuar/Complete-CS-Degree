**The time required for a packet to travel from an input to and output.**

Latency refers to the delay before a transfer of data begins following an instruction for its transfer. It is the time taken for data to travel from the source to the destination and is usually measured in milliseconds (ms).

In networking, latency can be influenced by various factors, including:

1. **Distance:** The physical distance between the source and destination can contribute to latency, as data must travel a longer distance over the network.
    
2. **Network Congestion:** High traffic on a network can lead to delays, as packets may have to wait in queues to be processed.
    
3. **Routing:** The paths that data packets take through routers and switches can affect latency, especially if they pass through multiple hops.
    
4. **Transmission Medium:** Different types of connections (fiber optics, copper cables, wireless, etc.) have varying latency characteristics.
    
5. **Processing Delays:** Time taken by devices (like routers, switches, or servers) to process data can also add to latency.
    

Lower latency is generally preferred, especially for applications requiring real-time data transfer, such as online gaming, video conferencing, or live streaming, where delays can significantly impact performance and user experience.

Tags:
[[Internet]]
[[Graph Theory]]